{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de63e87a",
   "metadata": {},
   "source": [
    "# 07. Software Development and Data Analysis Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee204eaf",
   "metadata": {},
   "source": [
    "# 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc18ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m60 packages\u001b[0m \u001b[2min 59ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 751ms\u001b[0m\u001b[0m0.4.1                           \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-community\u001b[0m\u001b[2m==1.0.0a1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-community\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install langchain~=1.0 langchain-core~=1.0 langchain-community~=0.4 langgraph~=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d3d6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m35 packages\u001b[0m \u001b[2min 549ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/362.77 KiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 14.91 KiB/362.77 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 14.91 KiB/362.77 KiB        \u001b[1A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 14.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 14.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 14.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 30.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 46.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 62.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 78.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 94.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 94.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 30.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 94.91 KiB/362.77 KiB        \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 30.85 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 110.91 KiB/362.77 KiB       \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 46.67 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 110.91 KiB/362.77 KiB       \u001b[2A\n",
      "\u001b[2mlangchain-anthropic \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 46.67 KiB/46.67 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 110.91 KiB/362.77 KiB       \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 110.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 126.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 142.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 158.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 174.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 190.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)2m------------\u001b[0m\u001b[0m 206.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)[2m-----------\u001b[0m\u001b[0m 222.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)\u001b[2m----------\u001b[0m\u001b[0m 238.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--\u001b[2m--------\u001b[0m\u001b[0m 254.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)---\u001b[2m-------\u001b[0m\u001b[0m 270.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[2m------\u001b[0m\u001b[0m 286.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)------\u001b[2m----\u001b[0m\u001b[0m 302.91 KiB/362.77 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 617ms\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/3] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 20ms\u001b[0m\u001b[0m7.0                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manthropic\u001b[0m\u001b[2m==0.74.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-anthropic\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install langchain-anthropic~=1.0 langchain-openai~=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51cc43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install python-dotenv~=1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaabc7",
   "metadata": {},
   "source": [
    "工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cde1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # By default, load_dotenv doesn't override existing environment variables and looks for a .env file in same directory as python script or searches for it incrementally higher up.\n",
    "        dotenv_path = dotenv.find_dotenv(usecwd=True)\n",
    "        if not dotenv_path:\n",
    "            raise ValueError(\"No .env file found\")\n",
    "        dotenv.load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY is not set\")\n",
    "\n",
    "        base_url = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "        if not base_url:\n",
    "            raise ValueError(\"OPENAI_API_BASE_URL is not set\")\n",
    "\n",
    "        model = os.getenv(\"OPENAI_MODEL\")\n",
    "        if not model:\n",
    "            raise ValueError(\"OPENAI_MODEL is not set\")\n",
    "\n",
    "        coder_model = os.getenv(\"OPENAI_CODER_MODEL\")\n",
    "        if not coder_model:\n",
    "            raise ValueError(\"OPENAI_MODEL is not set\")\n",
    "\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model = model\n",
    "        self.coder_model = coder_model\n",
    "\n",
    "        self.anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        self.anthropic_base_url = os.getenv(\"ANTHROPIC_BASE_URL\")\n",
    "        self.anthropic_model = os.getenv(\"ANTHROPIC_MODEL\")\n",
    "\n",
    "        self.embeddings_model = os.getenv(\"OPENAI_EMBEDDINGS_MODEL\")\n",
    "\n",
    "        hf_pretrained_embeddings_model = os.getenv(\"HF_PRETRAINED_EMBEDDINGS_MODEL\")\n",
    "        self.hf_pretrained_embeddings_model = (\n",
    "            hf_pretrained_embeddings_model\n",
    "            if hf_pretrained_embeddings_model\n",
    "            else \"Qwen/Qwen3-Embedding-8B\"\n",
    "        )\n",
    "\n",
    "    def new_anthropic(self, **kwargs) -> ChatAnthropic:\n",
    "        # 参考：https://bailian.console.aliyun.com/?tab=api#/api/?type=model&url=2587654\n",
    "        # 参考：https://help.aliyun.com/zh/model-studio/models\n",
    "        # ChatOpenAI 文档参考：https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI\n",
    "        return ChatAnthropic(\n",
    "            api_key=self.anthropic_api_key,\n",
    "            base_url=self.anthropic_base_url,\n",
    "            model=self.anthropic_model,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def new_openai_like_coder(self, **kwargs) -> ChatOpenAI:\n",
    "        # 参考：https://bailian.console.aliyun.com/?tab=api#/api/?type=model&url=2587654\n",
    "        # 参考：https://help.aliyun.com/zh/model-studio/models\n",
    "        # ChatOpenAI 文档参考：https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI\n",
    "        return ChatOpenAI(\n",
    "            api_key=self.api_key,\n",
    "            base_url=self.base_url,\n",
    "            model=self.coder_model,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def new_openai_like(self, **kwargs) -> ChatOpenAI:\n",
    "        # 参考：https://bailian.console.aliyun.com/?tab=api#/api/?type=model&url=2587654\n",
    "        # 参考：https://help.aliyun.com/zh/model-studio/models\n",
    "        # ChatOpenAI 文档参考：https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI\n",
    "        model = kwargs.pop(\"model\", self.model)\n",
    "        return ChatOpenAI(\n",
    "            api_key=self.api_key, base_url=self.base_url, model=model, **kwargs\n",
    "        )\n",
    "\n",
    "    def new_openai_like_embeddings(self, **kwargs) -> OpenAIEmbeddings:\n",
    "        if not self.embeddings_model:\n",
    "            raise ValueError(\"OPENAI_EMBEDDINGS_MODEL is not set\")\n",
    "        # print(\"embeddings_model:\", self.embeddings_model)\n",
    "\n",
    "        # 参考：https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html#langchain_openai.embeddings.base.OpenAIEmbeddings\n",
    "        return OpenAIEmbeddings(\n",
    "            api_key=self.api_key,\n",
    "            base_url=self.base_url,\n",
    "            model=self.embeddings_model,\n",
    "            # https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html#langchain_openai.embeddings.base.OpenAIEmbeddings.tiktoken_enabled\n",
    "            # 对于非 OpenAI 的官方实现，将这个参数置为 False。\n",
    "            # 回退到用 huggingface transformers 库 AutoTokenizer 来处理 token。\n",
    "            tiktoken_enabled=False,\n",
    "            # https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html#langchain_openai.embeddings.base.OpenAIEmbeddings.model\n",
    "            # 元宝说 Jina 的 embedding 模型 https://huggingface.co/jinaai/jina-embeddings-v4 最接近\n",
    "            # text-embedding-ada-002\n",
    "            # 个人喜好，选了 Qwen/Qwen3-Embedding-8B\n",
    "            # tiktoken_model_name='Qwen/Qwen3-Embedding-8B',\n",
    "            tiktoken_model_name=self.hf_pretrained_embeddings_model,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "def must_get_hfh_api_token() -> str:\n",
    "    \"\"\"\n",
    "    从环境变量或者 .env 环境获取 HuggingFaceHub 的 API 令牌\n",
    "    \"\"\"\n",
    "    # By default, load_dotenv doesn't override existing environment variables and looks for a .env file in same directory as python script or searches for it incrementally higher up.\n",
    "    dotenv_path = dotenv.find_dotenv(usecwd=True)\n",
    "    if not dotenv_path:\n",
    "        raise ValueError(\"No .env file found\")\n",
    "    dotenv.load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "    out = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "    if not out:\n",
    "        raise ValueError(\"HUGGINGFACEHUB_API_TOKEN is not set\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15e022",
   "metadata": {},
   "source": [
    "## LLMs in software development\n",
    "### The future of development\n",
    "### Implementation considerations\n",
    "### Evolution of code LLMs\n",
    "### Benchmarks for code LLMs\n",
    "### LLM-based software engineering approaches\n",
    "### Security and risk mitigation\n",
    "### Validation framework for LLM-generated code\n",
    "### LangChain integrations\n",
    "## Writing code with LLMs\n",
    "### Google generative AI\n",
    "replaced by Qwen as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8250d008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at this FizzBuzz problem, I need to iterate through numbers from 1 to n and apply the given conditions.\n",
      "\n",
      "Let me break down the logic:\n",
      "- If divisible by both 3 and 5 → \"FizzBuzz\"\n",
      "- If divisible by 3 only → \"Fizz\" \n",
      "- If divisible by 5 only → \"Buzz\"\n",
      "- Otherwise → the number as string\n",
      "\n",
      "Here's my solution:\n",
      "\n",
      "```python\n",
      "def fizzBuzz(n):\n",
      "    answer = []\n",
      "    \n",
      "    for i in range(1, n + 1):\n",
      "        if i % 3 == 0 and i % 5 == 0:\n",
      "            answer.append(\"FizzBuzz\")\n",
      "        elif i % 3 == 0:\n",
      "            answer.append(\"Fizz\")\n",
      "        elif i % 5 == 0:\n",
      "            answer.append(\"Buzz\")\n",
      "        else:\n",
      "            answer.append(str(i))\n",
      "    \n",
      "    return answer\n",
      "```\n",
      "\n",
      "Alternative approach (checking divisibility by 15 for cleaner code):\n",
      "\n",
      "```python\n",
      "def fizzBuzz(n):\n",
      "    answer = []\n",
      "    \n",
      "    for i in range(1, n + 1):\n",
      "        if i % 15 == 0:  # divisible by both 3 and 5\n",
      "            answer.append(\"FizzBuzz\")\n",
      "        elif i % 3 == 0:\n",
      "            answer.append(\"Fizz\")\n",
      "        elif i % 5 == 0:\n",
      "            answer.append(\"Buzz\")\n",
      "        else:\n",
      "            answer.append(str(i))\n",
      "    \n",
      "    return answer\n",
      "```\n",
      "\n",
      "**Time Complexity:** O(n) - single loop through n elements\n",
      "**Space Complexity:** O(n) - for the result array\n",
      "\n",
      "Example walkthrough with n=15:\n",
      "- 1 → \"1\"\n",
      "- 2 → \"2\" \n",
      "- 3 → \"Fizz\"\n",
      "- 4 → \"4\"\n",
      "- 5 → \"Buzz\"\n",
      "- 6 → \"Fizz\"\n",
      "- 9 → \"Fizz\"\n",
      "- 10 → \"Buzz\"\n",
      "- 15 → \"FizzBuzz\"\n",
      "\n",
      "The key insight is checking for divisibility by both 3 and 5 first (either as separate conditions or by checking divisibility by 15), since that's the most specific case.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Given an integer n, return a string array answer (1-indexed) where:\n",
    "\n",
    "answer[i] == \"FizzBuzz\" if i is divisible by 3 and 5.\n",
    "answer[i] == \"Fizz\" if i is divisible by 3.\n",
    "answer[i] == \"Buzz\" if i is divisible by 5.\n",
    "answer[i] == i (as a string) if none of the above conditions are true.\n",
    "\"\"\"\n",
    "\n",
    "llm = Config().new_openai_like_coder()\n",
    "\n",
    "# 调用 print 格式化输出\n",
    "print(llm.invoke(question).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7cecd1",
   "metadata": {},
   "source": [
    "### Hugging Face [没跑通]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9415eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "text = \"\"\"\n",
    "def calculate_primes(n):\n",
    "    \\\"\\\"\\\"Create a list of consecutive integers from 2 up to N.\n",
    "\n",
    "    For example:\n",
    "    >>> calculate_primes(20)\n",
    "    Output: [2, 3, 5, 7, 11, 13, 17, 19]\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61d5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 481ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/196.26 KiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/196.26 KiB          \u001b[1A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/552.83 KiB          \u001b[2A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/552.83 KiB          \u001b[2A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/552.83 KiB          \u001b[2A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/552.83 KiB          \u001b[3A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/552.83 KiB          \u001b[3A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/552.83 KiB          \u001b[3A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/552.83 KiB          \u001b[3A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/3.17 MiB            \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/3.17 MiB            \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/3.17 MiB            \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/3.17 MiB            \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 14.88 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/3.17 MiB            \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 14.88 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 14.88 KiB/3.17 MiB          \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 14.88 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 14.88 KiB/3.17 MiB          \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 14.88 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 14.88 KiB/3.17 MiB          \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 14.88 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 14.88 KiB/3.17 MiB          \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 14.88 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.88 KiB/3.17 MiB          \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 15.68 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.88 KiB/3.17 MiB          \u001b[4A\n",
      "\u001b[2mfilelock            \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 15.68 KiB/15.68 KiB\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.88 KiB/3.17 MiB          \u001b[4A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 46.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 46.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 46.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 46.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 46.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 46.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 46.84 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 46.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 61.93 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 46.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 61.93 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 46.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.88 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 61.93 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 62.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 61.93 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 62.88 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 76.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 77.84 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 76.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 77.84 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 92.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 93.84 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 107.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 108.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 93.84 KiB/3.17 MiB          \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 124.65 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 125.84 KiB/3.17 MiB         \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 139.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 140.65 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 125.84 KiB/3.17 MiB         \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 171.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 156.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 173.84 KiB/3.17 MiB         \u001b[3A\n",
      "\u001b[2mfsspec              \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 187.54 KiB/196.26 KiB\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 172.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 189.74 KiB/3.17 MiB         \u001b[3A\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 204.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 205.84 KiB/3.17 MiB         \u001b[2A\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 236.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 237.84 KiB/3.17 MiB         \u001b[2A\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 316.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/4)--------------\u001b[0m\u001b[0m 269.84 KiB/3.17 MiB         \u001b[2A\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 352.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/4)--------------\u001b[0m\u001b[0m 349.84 KiB/3.17 MiB         \u001b[2A\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 412.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/4)--------------\u001b[0m\u001b[0m 413.84 KiB/3.17 MiB         \u001b[2A\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 428.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/4)--------------\u001b[0m\u001b[0m 445.84 KiB/3.17 MiB         \u001b[2A\n",
      "\u001b[2mhuggingface-hub     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 540.75 KiB/552.83 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/4)--------------\u001b[0m\u001b[0m 493.84 KiB/3.17 MiB         \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/4)--------------\u001b[0m\u001b[0m 541.84 KiB/3.17 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)--------------\u001b[0m\u001b[0m 685.84 KiB/3.17 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)--------------\u001b[0m\u001b[0m 765.84 KiB/3.17 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)--------------\u001b[0m\u001b[0m 1021.84 KiB/3.17 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)--------------\u001b[0m\u001b[0m 1.21 MiB/3.17 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)--------------\u001b[0m\u001b[0m 1.34 MiB/3.17 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)--------------\u001b[0m\u001b[0m 1.64 MiB/3.17 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)[2m-----------\u001b[0m\u001b[0m 1.95 MiB/3.17 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)-\u001b[2m---------\u001b[0m\u001b[0m 2.20 MiB/3.17 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/4)-----\u001b[2m-----\u001b[0m\u001b[0m 2.62 MiB/3.17 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 1.83s\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/4] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m.0                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install huggingface-hub~=0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80021b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2771350/1608604917.py:7: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n",
      "/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'InferenceClient' object has no attribute 'post'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      7\u001b[39m llm = HuggingFaceHub(\n\u001b[32m      8\u001b[39m     repo_id=repo_id,\n\u001b[32m      9\u001b[39m     task=\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     model_kwargs={\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.5\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1000\u001b[39m},\n\u001b[32m     11\u001b[39m     huggingfacehub_api_token=must_get_hfh_api_token(),\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Use the LangChain LLM to generate text\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m output = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:392\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m     **kwargs: Any,\n\u001b[32m    389\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    390\u001b[39m     config = ensure_config(config)\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    403\u001b[39m         .text\n\u001b[32m    404\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:791\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    784\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m     **kwargs: Any,\n\u001b[32m    789\u001b[39m ) -> LLMResult:\n\u001b[32m    790\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1002\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    988\u001b[39m     run_managers = [\n\u001b[32m    989\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    990\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1000\u001b[39m         )\n\u001b[32m   1001\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m   1010\u001b[39m     run_managers = [\n\u001b[32m   1011\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m   1012\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1019\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m   1020\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:817\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    807\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    808\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    813\u001b[39m     **kwargs: Any,\n\u001b[32m    814\u001b[39m ) -> LLMResult:\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    816\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    821\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    824\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    825\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    826\u001b[39m         )\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    828\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1580\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1577\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1578\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1579\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1580\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1581\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1582\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1583\u001b[39m     )\n\u001b[32m   1584\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1585\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_community/llms/huggingface_hub.py:138\u001b[39m, in \u001b[36mHuggingFaceHub._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m _model_kwargs = \u001b[38;5;28mself\u001b[39m.model_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    136\u001b[39m parameters = {**_model_kwargs, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m(\n\u001b[32m    139\u001b[39m     json={\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: parameters}, task=\u001b[38;5;28mself\u001b[39m.task\n\u001b[32m    140\u001b[39m )\n\u001b[32m    141\u001b[39m response = json.loads(response.decode())\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[31mAttributeError\u001b[39m: 'InferenceClient' object has no attribute 'post'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# Choose a lightweight model good for code generation\n",
    "repo_id = \"bigcode/starcoder\"\n",
    "\n",
    "# Initialize the HuggingFaceHub LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=repo_id,\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 1000},\n",
    "    huggingfacehub_api_token=must_get_hfh_api_token(),\n",
    ")\n",
    "\n",
    "# Use the LangChain LLM to generate text\n",
    "output = llm.invoke(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb7c4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m32 packages\u001b[0m \u001b[2min 572ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/3.10 MiB            \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)---------------\u001b[0m\u001b[0m     0 B/3.10 MiB           \u001b[1A\n",
      "\u001b[2mlangchain-huggingface\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/26.96 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)---------------\u001b[0m\u001b[0m     0 B/3.10 MiB           \u001b[2A\n",
      "\u001b[2mlangchain-huggingface\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 16.00 KiB/26.96 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)---------------\u001b[0m\u001b[0m     0 B/3.10 MiB           \u001b[2A\n",
      "\u001b[2mlangchain-huggingface\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 26.96 KiB/26.96 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)---------------\u001b[0m\u001b[0m     0 B/3.10 MiB           \u001b[2A\n",
      "\u001b[2mlangchain-huggingface\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 26.96 KiB/26.96 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)---------------\u001b[0m\u001b[0m     0 B/3.10 MiB           \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m     0 B/3.10 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m     0 B/3.10 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 16.00 KiB/3.10 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 32.00 KiB/3.10 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 48.00 KiB/3.10 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 63.55 KiB/3.10 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 79.55 KiB/3.10 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 95.55 KiB/3.10 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 95.55 KiB/3.10 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 111.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 127.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 143.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 159.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 175.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 191.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 207.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 223.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 239.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 255.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 271.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 287.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 303.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 319.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 319.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 415.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 495.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 655.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 783.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 943.55 KiB/3.10 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 1.05 MiB/3.10 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 1.28 MiB/3.10 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------------\u001b[0m\u001b[0m 1.48 MiB/3.10 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)2m-------------\u001b[0m\u001b[0m 1.72 MiB/3.10 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-\u001b[2m----------\u001b[0m\u001b[0m 1.97 MiB/3.10 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[2m-------\u001b[0m\u001b[0m 2.28 MiB/3.10 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)------\u001b[2m-----\u001b[0m\u001b[0m 2.53 MiB/3.10 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 1.27s\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/2] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 20ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-huggingface\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install langchain-huggingface~=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ee097b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Provider 'huggingface' not supported. Available values: 'auto' or any provider from ['black-forest-labs', 'cerebras', 'clarifai', 'cohere', 'fal-ai', 'featherless-ai', 'fireworks-ai', 'groq', 'hf-inference', 'hyperbolic', 'nebius', 'novita', 'nscale', 'openai', 'publicai', 'replicate', 'sambanova', 'scaleway', 'together', 'zai-org'].Passing 'auto' (default value) will automatically select the first provider available for the model, sorted by the user's order in https://hf.co/settings/inference-providers.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     14\u001b[39m llm = HuggingFaceEndpoint(\n\u001b[32m     15\u001b[39m     repo_id=repo_id,\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# max_length=128,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# provider=\"together\",\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Use the LangChain LLM to generate text\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m output = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:392\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m     **kwargs: Any,\n\u001b[32m    389\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    390\u001b[39m     config = ensure_config(config)\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    403\u001b[39m         .text\n\u001b[32m    404\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:791\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    784\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m     **kwargs: Any,\n\u001b[32m    789\u001b[39m ) -> LLMResult:\n\u001b[32m    790\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1002\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    988\u001b[39m     run_managers = [\n\u001b[32m    989\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    990\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1000\u001b[39m         )\n\u001b[32m   1001\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m   1010\u001b[39m     run_managers = [\n\u001b[32m   1011\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m   1012\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1019\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m   1020\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:817\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    807\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    808\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    813\u001b[39m     **kwargs: Any,\n\u001b[32m    814\u001b[39m ) -> LLMResult:\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    816\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    821\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    824\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    825\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    826\u001b[39m         )\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    828\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1580\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1577\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1578\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1579\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1580\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1581\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1582\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1583\u001b[39m     )\n\u001b[32m   1584\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1585\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_huggingface/llms/huggingface_endpoint.py:318\u001b[39m, in \u001b[36mHuggingFaceEndpoint._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    315\u001b[39m         completion += chunk.text\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m response_text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minvocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stop_seq \u001b[38;5;129;01min\u001b[39;00m invocation_params[\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2356\u001b[39m, in \u001b[36mInferenceClient.text_generation\u001b[39m\u001b[34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[39m\n\u001b[32m   2350\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2351\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAPI endpoint/model for text-generation is not served via TGI. Cannot return output as a stream.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2352\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Please pass `stream=False` as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2353\u001b[39m         )\n\u001b[32m   2355\u001b[39m model_id = model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m-> \u001b[39m\u001b[32m2356\u001b[39m provider_helper = \u001b[43mget_provider_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2357\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m   2358\u001b[39m     inputs=prompt,\n\u001b[32m   2359\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2363\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m   2364\u001b[39m )\n\u001b[32m   2366\u001b[39m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_providers/__init__.py:221\u001b[39m, in \u001b[36mget_provider_helper\u001b[39m\u001b[34m(provider, task, model)\u001b[39m\n\u001b[32m    219\u001b[39m provider_tasks = PROVIDERS.get(provider)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider_tasks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProvider \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not supported. Available values: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or any provider from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(PROVIDERS.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing \u001b[39m\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (default value) will automatically select the first provider available for the model, sorted \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mby the user\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms order in https://hf.co/settings/inference-providers.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m     )\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m provider_tasks:\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    229\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTask \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not supported for provider \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Available tasks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(provider_tasks.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    230\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Provider 'huggingface' not supported. Available values: 'auto' or any provider from ['black-forest-labs', 'cerebras', 'clarifai', 'cohere', 'fal-ai', 'featherless-ai', 'fireworks-ai', 'groq', 'hf-inference', 'hyperbolic', 'nebius', 'novita', 'nscale', 'openai', 'publicai', 'replicate', 'sambanova', 'scaleway', 'together', 'zai-org'].Passing 'auto' (default value) will automatically select the first provider available for the model, sorted by the user's order in https://hf.co/settings/inference-providers."
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Choose a lightweight model good for code generation\n",
    "repo_id = \"bigcode/starcoder\"\n",
    "\n",
    "# Initialize the HuggingFaceHub LLM\n",
    "# llm = HuggingFaceHub(\n",
    "#     repo_id=repo_id,\n",
    "#     task=\"text-generation\",\n",
    "#     model_kwargs={\"temperature\": 0.5, \"max_length\": 1000},\n",
    "#     huggingfacehub_api_token=must_get_hfh_api_token(),\n",
    "# )\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    # max_length=128,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=must_get_hfh_api_token(),\n",
    "    provider=\"huggingface\",  # set your provider here hf.co/settings/inference-providers\n",
    "    # provider=\"hyperbolic\",\n",
    "    # provider=\"nebius\",\n",
    "    # provider=\"together\",\n",
    ")\n",
    "\n",
    "# Use the LangChain LLM to generate text\n",
    "output = llm.invoke(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4caa5",
   "metadata": {},
   "source": [
    "### Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456847f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "text = \"\"\"\n",
    "def calculate_primes(n):\n",
    "    \\\"\\\"\\\"Create a list of consecutive integers from 2 up to N.\n",
    "\n",
    "    For example:\n",
    "    >>> calculate_primes(20)\n",
    "    Output: [2, 3, 5, 7, 11, 13, 17, 19]\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb6ae489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to implement the `calculate_primes` function that returns all prime numbers from 2 up to n using the Sieve of Eratosthenes algorithm.\n",
      "\n",
      "Let me think through the steps:\n",
      "\n",
      "1. Create a boolean list to track which numbers are prime (initially assume all are prime)\n",
      "2. Mark 0 and 1 as non-prime (though we start from 2 anyway)\n",
      "3. Iterate through numbers from 2 to √n\n",
      "4. For each prime number found, mark all its multiples as non-prime\n",
      "5. Collect all numbers that remain marked as prime\n",
      "\n",
      "Here's my implementation:\n",
      "\n",
      "```python\n",
      "def calculate_primes(n):\n",
      "    \"\"\"Create a list of consecutive integers from 2 up to N.\n",
      "\n",
      "    For example:\n",
      "    >>> calculate_primes(20)\n",
      "    Output: [2, 3, 5, 7, 11, 13, 17, 19]\n",
      "    \"\"\"\n",
      "    if n < 2:\n",
      "        return []\n",
      "    \n",
      "    # Create a boolean list \"prime[0..n]\" and initialize all entries as True\n",
      "    prime = [True] * (n + 1)\n",
      "    prime[0] = prime[1] = False  # 0 and 1 are not prime numbers\n",
      "    \n",
      "    # Start with the first prime number, 2\n",
      "    p = 2\n",
      "    while p * p <= n:\n",
      "        # If prime[p] is not changed, then it is a prime\n",
      "        if prime[p]:\n",
      "            # Update all multiples of p starting from p*p\n",
      "            for i in range(p * p, n + 1, p):\n",
      "                prime[i] = False\n",
      "        p += 1\n",
      "    \n",
      "    # Collect all prime numbers\n",
      "    primes = []\n",
      "    for i in range(2, n + 1):\n",
      "        if prime[i]:\n",
      "            primes.append(i)\n",
      "    \n",
      "    return primes\n",
      "```\n",
      "\n",
      "This implementation uses the Sieve of Eratosthenes algorithm which efficiently finds all prime numbers up to n by:\n",
      "1. Creating a list of all integers from 2 to n\n",
      "2. Marking multiples of each prime as composite\n",
      "3. Returning the numbers that remain unmarked (prime)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Let's think step by step.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = Config().new_anthropic()\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "print(llm_chain.invoke(text).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f73fb",
   "metadata": {},
   "source": [
    "### Agentic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748d3870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m47 packages\u001b[0m \u001b[2min 63ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 93ms\u001b[0m\u001b[0mal==0.4.0                        \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-experimental\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install 'langchain-experimental~=0.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af347e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What is 2 + 2?', additional_kwargs={}, response_metadata={}, id='fbbfb1c6-49c2-4142-a20e-206360047b44')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='2 + 2 equals 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 296, 'total_tokens': 304, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen3-max-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-ea6b695d-92cf-4a87-aa44-4db8b499cb0a', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b0eb46b0-adc6-4c23-a614-75cd95d0edcb-0', usage_metadata={'input_tokens': 296, 'output_tokens': 8, 'total_tokens': 304, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What is 2 + 2?', additional_kwargs={}, response_metadata={}, id='fbbfb1c6-49c2-4142-a20e-206360047b44'), AIMessage(content='2 + 2 equals 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 296, 'total_tokens': 304, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen3-max-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-ea6b695d-92cf-4a87-aa44-4db8b499cb0a', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b0eb46b0-adc6-4c23-a614-75cd95d0edcb-0', usage_metadata={'input_tokens': 296, 'output_tokens': 8, 'total_tokens': 304, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "responses = [\"Action: Python_REPL\\nAction Input: print(2 + 2)\", \"Final Answer: 4\"]\n",
    "llm = Config().new_openai_like()\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "agent = create_agent(model=llm, tools=tools, debug=True)\n",
    "\n",
    "input = {\"messages\": [(\"user\", \"What is 2 + 2?\")]}\n",
    "result = agent.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886cab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85830ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What are the prime numbers until 20?', additional_kwargs={}, response_metadata={}, id='61f44c19-5f8d-4b09-a57c-b191f88c7b05')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 321, 'total_tokens': 419, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-bf92b640-22bc-4e59-9e78-02cf44a359d3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--fe76469b-6b80-47f2-8797-69ad9a31374f-0', tool_calls=[{'name': 'Python_REPL', 'args': {'query': 'def is_prime(n):\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\nprime_numbers = [n for n in range(2, 21) if is_prime(n)]\\nprint(prime_numbers)'}, 'id': 'call_d0fc7f7b8a114d529f13e0cb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 321, 'output_tokens': 98, 'total_tokens': 419, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What are the prime numbers until 20?', additional_kwargs={}, response_metadata={}, id='61f44c19-5f8d-4b09-a57c-b191f88c7b05'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 321, 'total_tokens': 419, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-bf92b640-22bc-4e59-9e78-02cf44a359d3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--fe76469b-6b80-47f2-8797-69ad9a31374f-0', tool_calls=[{'name': 'Python_REPL', 'args': {'query': 'def is_prime(n):\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\nprime_numbers = [n for n in range(2, 21) if is_prime(n)]\\nprint(prime_numbers)'}, 'id': 'call_d0fc7f7b8a114d529f13e0cb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 321, 'output_tokens': 98, 'total_tokens': 419, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='[2, 3, 5, 7, 11, 13, 17, 19]\\n', name='Python_REPL', id='79c0e305-5665-4808-bc87-5050363a6a4e', tool_call_id='call_d0fc7f7b8a114d529f13e0cb')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What are the prime numbers until 20?', additional_kwargs={}, response_metadata={}, id='61f44c19-5f8d-4b09-a57c-b191f88c7b05'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 321, 'total_tokens': 419, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-bf92b640-22bc-4e59-9e78-02cf44a359d3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--fe76469b-6b80-47f2-8797-69ad9a31374f-0', tool_calls=[{'name': 'Python_REPL', 'args': {'query': 'def is_prime(n):\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\nprime_numbers = [n for n in range(2, 21) if is_prime(n)]\\nprint(prime_numbers)'}, 'id': 'call_d0fc7f7b8a114d529f13e0cb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 321, 'output_tokens': 98, 'total_tokens': 419, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}), ToolMessage(content='[2, 3, 5, 7, 11, 13, 17, 19]\\n', name='Python_REPL', id='79c0e305-5665-4808-bc87-5050363a6a4e', tool_call_id='call_d0fc7f7b8a114d529f13e0cb')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='The prime numbers until 20 are: 2, 3, 5, 7, 11, 13, 17, and 19.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 461, 'total_tokens': 499, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-657bab1c-ed27-4792-bc29-055bd32459cc', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d7c17cb3-2956-4eac-a846-f06db9d2eaab-0', usage_metadata={'input_tokens': 461, 'output_tokens': 38, 'total_tokens': 499, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What are the prime numbers until 20?', additional_kwargs={}, response_metadata={}, id='61f44c19-5f8d-4b09-a57c-b191f88c7b05'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 321, 'total_tokens': 419, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-bf92b640-22bc-4e59-9e78-02cf44a359d3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--fe76469b-6b80-47f2-8797-69ad9a31374f-0', tool_calls=[{'name': 'Python_REPL', 'args': {'query': 'def is_prime(n):\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\nprime_numbers = [n for n in range(2, 21) if is_prime(n)]\\nprint(prime_numbers)'}, 'id': 'call_d0fc7f7b8a114d529f13e0cb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 321, 'output_tokens': 98, 'total_tokens': 419, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}), ToolMessage(content='[2, 3, 5, 7, 11, 13, 17, 19]\\n', name='Python_REPL', id='79c0e305-5665-4808-bc87-5050363a6a4e', tool_call_id='call_d0fc7f7b8a114d529f13e0cb'), AIMessage(content='The prime numbers until 20 are: 2, 3, 5, 7, 11, 13, 17, and 19.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 461, 'total_tokens': 499, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus-2025-09-23', 'system_fingerprint': None, 'id': 'chatcmpl-657bab1c-ed27-4792-bc29-055bd32459cc', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d7c17cb3-2956-4eac-a846-f06db9d2eaab-0', usage_metadata={'input_tokens': 461, 'output_tokens': 38, 'total_tokens': 499, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "llm = Config().new_openai_like_coder()\n",
    "\n",
    "agent = create_agent(model=llm, tools=tools, debug=True)\n",
    "\n",
    "input = {\"messages\": [(\"user\", \"What are the prime numbers until 20?\")]}\n",
    "result = agent.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3607de35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prime numbers until 20 are: 2, 3, 5, 7, 11, 13, 17, and 19.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8c99b",
   "metadata": {},
   "source": [
    "### Documentation RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ec319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install beautifulsoup4~=4.14 lxml~=6.0 nest-asyncio~=1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f38cd2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Fetching pages:  51%|#####1    | 248/483 [02:36<03:00,  1.30it/s]Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7f2c269f1640> is already entered\n",
      "Fetching pages:  52%|#####1    | 250/483 [02:37<02:47,  1.39it/s]Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7f2c269f1640> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7f2c269f1640> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7f2c269f1640> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7f2c269f1640> is already entered\n",
      "Fetching pages:  52%|#####2    | 253/483 [02:38<02:16,  1.69it/s]Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7f2c269f1640> is already entered\n",
      "Fetching pages: 100%|##########| 483/483 [06:01<00:00,  1.34it/s]\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1720' coro=<_async_in_context.<locals>.run_in_context() done, defined at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-1721' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/bs4/builder/__init__.py:423: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  modified_value = self.attribute_value_list_class(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1721' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1729' coro=<_async_in_context.<locals>.run_in_context() done, defined at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-1730' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1730' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1732' coro=<_async_in_context.<locals>.run_in_context() done, defined at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-1733' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1733' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1735' coro=<_async_in_context.<locals>.run_in_context() done, defined at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-1736' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1736' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1741' coro=<_async_in_context.<locals>.run_in_context() done, defined at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-1742' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1742' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1747' coro=<_async_in_context.<locals>.run_in_context() done, defined at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-1748' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-1748' coro=<Kernel.shell_main() running at /github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DocusaurusLoader\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "loader = DocusaurusLoader(\"https://docs.langchain.com\")\n",
    "# TODO: 解决内存不足导致加载很慢的问题\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd790a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://docs.langchain.com', 'loc': 'https://docs.langchain.com', 'lastmod': '2025-11-17T20:55:52.292Z'}, page_content=\"Home - Docs by LangChainSkip to main content🚀 Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageHomeSearch...⌘KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationDocumentationLangChain is the platform for agent engineering. AI teams at Replit, Clay, Rippling, Cloudflare, Workday, and more trust LangChain’s products to engineer reliable agents.Open source agent frameworks Python TypeScriptLangChain (Python)Quickly get started building agents, with any model provider of your choice.Learn moreLangGraph (Python)Control every step of your custom agent with low-level orchestration, memory, and human-in-the-loop support.Learn moreDeep Agents (Python)Build agents that can tackle complex, multi-step tasks.Learn moreLangSmithLangSmith is a platform that helps AI teams use live production data for continuous testing and improvement. LangSmith provides:ObservabilitySee exactly how your agent thinks and acts with detailed tracing and aggregate trend metrics.Learn moreEvaluationTest and score agent behavior on production data or offline datasets to continuously improve performance.Learn morePrompt EngineeringIterate on prompts with version control, prompt optimization, and collaboration features.Learn moreDeploymentShip your agent in one click, using scalable infrastructure built for long-running tasks.Learn moreLangSmith meets the highest standards of data security and privacy with HIPAA, SOC 2 Type 2, and GDPR compliance. For more information, see the Trust Center.Get startedBuild your first agent with LangChainGet startedSign up for LangSmithTry LangSmithBuild an advanced agent with LangGraphGet startedEnroll in LangChain AcademyGet started\\n\\n\\nEdit the source of this page on GitHub.\\nConnect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3a47b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/langchain_classic/embeddings/cache.py:58: UserWarning: Using default key encoder: SHA-1 is *not* collision-resistant. While acceptable for most cache scenarios, a motivated attacker can craft two different payloads that map to the same cache key. If that risk matters in your environment, supply a stronger encoder (e.g. SHA-256 or BLAKE2) via the `key_encoder` argument. If you change the key encoder, consider also creating a new cache, to avoid (the potential for) collisions with existing keys.\n",
      "  _warn_about_sha1_encoder()\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.embeddings import CacheBackedEmbeddings\n",
    "from langchain_classic.storage import LocalFileStore\n",
    "\n",
    "\n",
    "store = LocalFileStore(\"./_cache/\")\n",
    "\n",
    "underlying_embeddings = Config().new_openai_like_embeddings()\n",
    "\n",
    "# Avoiding unnecessary costs by caching the embeddings.\n",
    "embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings, store, namespace=underlying_embeddings.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6dff337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m26 packages\u001b[0m \u001b[2min 169ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 18ms\u001b[0m\u001b[0mters==0.3.11                     \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==0.3.11\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install langchain-text-splitters~=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42bed5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5568a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m18 packages\u001b[0m \u001b[2min 1.01s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/11.44 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 14.90 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 14.90 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 30.90 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 46.90 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 62.90 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 76.43 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 76.43 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 92.43 KiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 108.43 KiB/11.44 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 124.43 KiB/11.44 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 140.43 KiB/11.44 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 140.43 KiB/11.44 MiB        \u001b[1A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 140.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 140.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 156.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 172.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 172.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 188.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 204.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 204.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 220.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 46.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 220.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 46.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 236.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 62.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 236.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 62.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 236.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 62.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 252.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 62.91 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 268.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 78.80 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 268.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 78.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 268.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 78.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 284.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 78.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 300.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 78.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 316.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 78.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 332.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 94.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 332.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 94.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 348.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 142.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 396.33 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 174.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 396.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 254.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 428.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 270.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 476.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 270.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 524.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 350.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 588.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 398.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 684.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 446.89 KiB/474.45 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m 732.43 KiB/11.44 MiB        \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 732.43 KiB/11.44 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 764.43 KiB/11.44 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 892.43 KiB/11.44 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.01 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.15 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.32 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.58 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.69 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.84 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.11 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.34 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.70 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 3.02 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 3.39 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 3.76 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 4.22 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 4.67 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 5.34 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 5.89 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)2m------------\u001b[0m\u001b[0m 6.62 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)\u001b[2m----------\u001b[0m\u001b[0m 7.31 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--\u001b[2m--------\u001b[0m\u001b[0m 8.03 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---\u001b[2m-------\u001b[0m\u001b[0m 8.72 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-----\u001b[2m-----\u001b[0m\u001b[0m 9.39 MiB/11.44 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-------\u001b[2m---\u001b[0m\u001b[0m 10.06 MiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------\u001b[2m-\u001b[0m\u001b[0m 10.72 MiB/11.44 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 2.65s\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/2] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 99ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install langchain-chroma~=0.2\n",
    "%uv pip install transformers~=4.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# qwen 的向量化模型支持的批次大小最大为 10，具体参见\n",
    "# https://bailian.console.aliyun.com/?spm=5176.12818093_47.console-base_search-panel.dtab-product_sfm.57ea16d0OEDXRx&scm=20140722.S_sfm._.ID_sfm-RL_%E7%99%BE%E7%82%BC-LOC_console_console-OR_ser-V_4-P0_0&tab=doc#/doc/?type=model&url=2842587\n",
    "# 批次过大会导致 qwen 的向量化模型报错\n",
    "# 这一步添加的页面比较多时，会耗时比较久\n",
    "#\n",
    "# vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "vectorstore = Chroma.from_documents(documents=splits[0:10], embedding=embeddings)\n",
    "for i in range(10, len(splits), 10):\n",
    "    batch = splits[i : i + 10]\n",
    "    vectorstore.add_documents(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3896aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Config().new_openai_like(model=\"qwen-plus-2025-09-11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a55f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cc0e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f72b1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down complex tasks into smaller, simpler steps, often using the Chain of Thought (CoT) method. Common extensions include planning components and leveraging plugins or self-defined modules to enhance execution. This approach improves problem-solving by enabling step-by-step reasoning and modular task handling.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318513a8",
   "metadata": {},
   "source": [
    "### Repository RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ff8b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 72ms\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/3] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 33ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.45\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install GitPython~=3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cf3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Clone the book repository from GitHub\n",
    "repo_path = os.path.expanduser(\"_generative_ai_with_langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36561b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "\n",
    "\n",
    "# this directory should not exist yet!\n",
    "repo = Repo.clone_from(\n",
    "    \"https://github.com/benman1/generative_ai_with_langchain\", to_path=repo_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7eb8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    repo_path,\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"],\n",
    "    parser=LanguageParser(language=\"python\", parser_threshold=500),\n",
    ")\n",
    "documents = loader.load()\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "# Split the Document into chunks for embedding and vector storage\n",
    "texts = python_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c861394a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m18 packages\u001b[0m \u001b[2min 108ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/7] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m7 packages\u001b[0m \u001b[2min 2.11s\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install transformers~=4.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6cdb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 24ms\u001b[0m\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install langchain-classic~=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "addfebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m92 packages\u001b[0m \u001b[2min 673ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/12.17 KiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----------\u001b[2m\u001b[0m\u001b[0m 12.17 KiB/12.17 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----------\u001b[2m\u001b[0m\u001b[0m 12.17 KiB/12.17 KiB         \u001b[1A\n",
      "\u001b[2mlangchain-chroma    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.17 KiB/12.17 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/20.40 MiB           \u001b[2A\n",
      "\u001b[2mlangchain-chroma    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.17 KiB/12.17 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/20.40 MiB           \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)--------------\u001b[0m\u001b[0m     0 B/20.40 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 14.91 KiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 14.91 KiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 30.91 KiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 46.91 KiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 62.91 KiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 78.91 KiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 94.91 KiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 110.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 126.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 142.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 142.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 158.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 174.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 190.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 206.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 222.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 238.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 254.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 270.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 286.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 302.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 318.91 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 408.56 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 456.56 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 616.56 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 722.38 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 914.38 KiB/20.40 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.02 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.28 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.57 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.73 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 1.87 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.22 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.57 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 2.75 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 3.11 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 3.38 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 3.87 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 4.14 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 4.64 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 5.02 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 5.63 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 6.34 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 6.83 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 7.38 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 8.48 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 9.09 MiB/20.40 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 10.06 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------------\u001b[0m\u001b[0m 10.76 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)m-------------\u001b[0m\u001b[0m 11.53 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)2m------------\u001b[0m\u001b[0m 12.21 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)[2m-----------\u001b[0m\u001b[0m 12.84 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-\u001b[2m---------\u001b[0m\u001b[0m 13.70 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--\u001b[2m--------\u001b[0m\u001b[0m 14.36 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---\u001b[2m-------\u001b[0m\u001b[0m 15.05 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[2m------\u001b[0m\u001b[0m 15.71 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-----\u001b[2m-----\u001b[0m\u001b[0m 16.45 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)------\u001b[2m----\u001b[0m\u001b[0m 17.14 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)-------\u001b[2m---\u001b[0m\u001b[0m 17.81 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)--------\u001b[2m--\u001b[0m\u001b[0m 18.43 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)---------\u001b[2m-\u001b[0m\u001b[0m 19.17 MiB/20.40 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 2.52s\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/55] \u001b[2mInstalling wheels...                                \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m55 packages\u001b[0m \u001b[2min 1.31s\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbcrypt\u001b[0m\u001b[2m==5.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbuild\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcachetools\u001b[0m\u001b[2m==6.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchromadb\u001b[0m\u001b[2m==1.3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdurationpy\u001b[0m\u001b[2m==0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflatbuffers\u001b[0m\u001b[2m==25.9.23\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.43.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.72.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema-specifications\u001b[0m\u001b[2m==2025.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkubernetes\u001b[0m\u001b[2m==34.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-chroma\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmmh3\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moauthlib\u001b[0m\u001b[2m==3.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-common\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-grpc\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-proto\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.59b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moverrides\u001b[0m\u001b[2m==7.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mposthog\u001b[0m\u001b[2m==5.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypika\u001b[0m\u001b[2m==0.48.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyproject-hooks\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mreferencing\u001b[0m\u001b[2m==0.37.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-oauthlib\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrpds-py\u001b[0m\u001b[2m==0.29.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsocket-client\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.23.0\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install langchain-chroma~=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8642d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/github.com/sammyne/generative-ai-with-lang-chain-2ed/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Store the documents in a vector store\n",
    "db = Chroma.from_documents(texts[0:10], Config().new_openai_like_embeddings())\n",
    "# qwen 的向量化模型支持的批次大小最大为 10，具体参见\n",
    "# https://bailian.console.aliyun.com/?spm=5176.12818093_47.console-base_search-panel.dtab-product_sfm.57ea16d0OEDXRx&scm=20140722.S_sfm._.ID_sfm-RL_%E7%99%BE%E7%82%BC-LOC_console_console-OR_ser-V_4-P0_0&tab=doc#/doc/?type=model&url=2842587\n",
    "for i in range(10, len(texts), 10):\n",
    "    batch = texts[i : i + 10]\n",
    "    db.add_documents(batch)\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 8})\n",
    "\n",
    "# Create a retrieval chain for Q&A over code\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "llm = Config().new_openai_like()\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9752ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the code referenced includes:\n",
      "\n",
      "- An example usage in the **main execution block**.\n",
      "- Code written in **PEP8 syntax** (the standard style guide for Python).\n",
      "- A link to an example file in a GitHub repository:  \n",
      "  https://github.com/ajndkr/lanarky/blob/main/examp  \n",
      "  (Note: The URL appears to be truncated, so the full path or filename isn’t visible.)\n",
      "- A reference to **chapter7.software_development.python_developer**, suggesting the example is part of educational or tutorial material focused on Python software development.\n",
      "\n",
      "While the exact details of the example aren't fully visible, it likely demonstrates **Python software development best practices**, possibly including structured code organization, error handling, and adherence to PEP8 standards. For precise content, you’d need to view the complete file at the GitHub link.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question from the book\n",
    "question = \"What examples are in the code related to software development?\"\n",
    "result = qa.invoke({\"input\": question})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1fa52",
   "metadata": {},
   "source": [
    "## Applying LLM agents for data science\n",
    "### Training an ML model\n",
    "#### Setting up a Python-capable agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174c95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits.python.base import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_classic.agents.agent_types import AgentType\n",
    "\n",
    "\n",
    "llm = Config().new_openai_like_coder()\n",
    "\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee32ce4",
   "metadata": {},
   "source": [
    "#### Asking the agent to build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b40ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3310160/4285791411.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
      "  result = agent_executor.run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to write a single neuron neural network in PyTorch that learns the relationship y=2x. Here are the steps:\n",
      "1. Generate synthetic data where y=2x\n",
      "2. Create a simple neural network with one neuron\n",
      "3. Train the network for 1000 epochs, printing loss every 100 epochs\n",
      "4. Make a prediction for x=5\n",
      "\n",
      "I'll start by importing the necessary libraries and creating the synthetic data.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: ```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "\n",
      "# Generate synthetic data for y = 2x\n",
      "x = torch.linspace(-10, 10, 100).reshape(-1, 1)\n",
      "y = 2 * x\n",
      "\n",
      "print(f\"Shape of x: {x.shape}\")\n",
      "print(f\"Shape of y: {y.shape}\")\n",
      "print(f\"First few values of x: {x[:5]}\")\n",
      "print(f\"First few values of y: {y[:5]}\")\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mModuleNotFoundError(\"No module named 'torch'\")\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to install PyTorch first using the uv pip command as instructed. Let me do that.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: ```bash\n",
      "uv pip install torch\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError('invalid syntax', ('<string>', 2, 4, 'uv pip install torch\\n', 2, 7))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to install PyTorch first. Since I'm getting a syntax error with the uv pip command, I'll try using the subprocess module to execute the command properly.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: ```python\n",
      "import subprocess\n",
      "import sys\n",
      "\n",
      "# Install PyTorch using uv pip\n",
      "result = subprocess.run([sys.executable, \"-m\", \"uv\", \"pip\", \"install\", \"torch\"], capture_output=True, text=True)\n",
      "print(\"Installation result:\", result.returncode)\n",
      "print(\"Installation stdout:\", result.stdout)\n",
      "print(\"Installation stderr:\", result.stderr)\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mInstallation result: 0\n",
      "Installation stdout: \n",
      "Installation stderr: \u001b[2mResolved \u001b[1m26 packages\u001b[0m \u001b[2min 95ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m21 packages\u001b[0m \u001b[2min 48.68s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.1\u001b[0m\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that PyTorch is installed, I can proceed with creating the single neuron neural network. Let me continue with the implementation:\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: ```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "\n",
      "# Generate synthetic data for y = 2x\n",
      "x = torch.linspace(-10, 10, 100).reshape(-1, 1)\n",
      "y = 2 * x\n",
      "\n",
      "print(f\"Shape of x: {x.shape}\")\n",
      "print(f\"Shape of y: {y.shape}\")\n",
      "print(f\"First few values of x: {x[:5]}\")\n",
      "print(f\"First few values of y: {y[:5]}\")\n",
      "\n",
      "# Define a simple neural network with one neuron\n",
      "class SingleNeuronNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(SingleNeuronNet, self).__init__()\n",
      "        self.linear = nn.Linear(1, 1)  # One input, one output\n",
      "    \n",
      "    def forward(self, x):\n",
      "        return self.linear(x)\n",
      "\n",
      "# Initialize the model\n",
      "model = SingleNeuronNet()\n",
      "\n",
      "# Define loss function and optimizer\n",
      "criterion = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
      "\n",
      "# Training loop\n",
      "for epoch in range(1000):\n",
      "    # Forward pass\n",
      "    predictions = model(x)\n",
      "    \n",
      "    # Calculate loss\n",
      "    loss = criterion(predictions, y)\n",
      "    \n",
      "    # Backward pass and optimization\n",
      "    optimizer.zero_grad()\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    \n",
      "    # Print loss every 100 epochs\n",
      "    if (epoch + 1) % 100 == 0:\n",
      "        print(f\"Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}\")\n",
      "\n",
      "# Make prediction for x = 5\n",
      "x_test = torch.tensor([[5.0]])\n",
      "prediction = model(x_test)\n",
      "print(f\"Prediction for x = 5: {prediction.item():.4f}\")\n",
      "\n",
      "# Print the learned parameters\n",
      "print(f\"Learned weight: {model.linear.weight.item():.4f}\")\n",
      "print(f\"Learned bias: {model.linear.bias.item():.4f}\")\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mShape of x: torch.Size([100, 1])\n",
      "Shape of y: torch.Size([100, 1])\n",
      "First few values of x: tensor([[-10.0000],\n",
      "        [ -9.7980],\n",
      "        [ -9.5960],\n",
      "        [ -9.3939],\n",
      "        [ -9.1919]])\n",
      "First few values of y: tensor([[-20.0000],\n",
      "        [-19.5960],\n",
      "        [-19.1919],\n",
      "        [-18.7879],\n",
      "        [-18.3838]])\n",
      "Epoch [100/1000], Loss: 0.0083\n",
      "Epoch [200/1000], Loss: 0.0001\n",
      "Epoch [300/1000], Loss: 0.0000\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "Prediction for x = 5: 10.0000\n",
      "Learned weight: 2.0000\n",
      "Learned bias: -0.0000\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully created and trained a single neuron neural network in PyTorch to learn the relationship y=2x. The network was trained for 1000 epochs, with the loss printed every 100 epochs. The prediction for x=5 is 10.0000, which is correct since y=2*5=10.\n",
      "\n",
      "Final Answer: The prediction for x = 5 is 10.0000.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.run(\n",
    "    \"Assume you are working in a jupyter notebook environment.\\n\"\n",
    "    \"Replace all `pip` command with `uv pip` for managing dependencies.\\n\"\n",
    "    \"\"\"Understand, write a single neuron neural network in PyTorch.\n",
    "Take synthetic data for y=2x. Train for 1000 epochs and print every 100 epochs.\n",
    "Return prediction for x = 5\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbbfa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for x = 5 is 10.0000.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f16ee",
   "metadata": {},
   "source": [
    "#### Agent execution and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7826d9",
   "metadata": {},
   "source": [
    "### Analyzing a dataset\n",
    "#### Creating a pandas DataFrame agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638af9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m11 packages\u001b[0m \u001b[2min 100ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/8] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m8 packages\u001b[0m \u001b[2min 1.25s\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install pandas~=2.3 scikit-learn~=1.7 tabulate~=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1b9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df = load_iris(as_frame=True)[\"data\"]\n",
    "\n",
    "df.to_csv(\"iris.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34bde905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7eecbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents import (\n",
    "    create_pandas_dataframe_agent,\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "PROMPT = (\n",
    "    \"If you do not know the answer, say you don't know.\\n\"\n",
    "    \"Think step by step.\\n\"\n",
    "    \"\\n\"\n",
    "    \"Below is the query.\\n\"\n",
    "    \"Query: {query}\\n\"\n",
    ")\n",
    "prompt = PromptTemplate(template=PROMPT, input_variables=[\"query\"])\n",
    "\n",
    "llm = Config().new_openai_like()\n",
    "# llm = Config().new_openai_like_coder()\n",
    "\n",
    "agent = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ef31f",
   "metadata": {},
   "source": [
    "#### Asking questions about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2d70a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The dataset appears to contain measurements related to flowers, specifically sepal and petal dimensions. These are typical features in the well-known Iris dataset, which is commonly used for classification tasks in machine learning. However, to confirm this and provide a precise answer, I should check if there's a column indicating the species or any metadata about the dataset. Since only the first few rows of numerical features are shown, I cannot definitively determine the exact context without more information.\n",
      "\n",
      "Final Answer: This dataset appears to be the Iris dataset, which contains measurements (sepal length, sepal width, petal length, and petal width) of iris flowers. It is commonly used for classification tasks in machine learning. However, without additional information such as a \"species\" column or metadata, this cannot be confirmed definitively.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This dataset appears to be the Iris dataset, which contains measurements (sepal length, sepal width, petal length, and petal width) of iris flowers. It is commonly used for classification tasks in machine learning. However, without additional information such as a \"species\" column or metadata, this cannot be confirmed definitively.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(prompt.format(query=\"What's this dataset about?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "773a18b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the row with the maximum value in the `petal_diff` column, which already represents the difference between petal length and petal width. I can use `idxmax()` to get the index of the row with the largest `petal_diff`.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['petal_diff'].idxmax()\u001b[0m\u001b[36;1m\u001b[1;3m122\u001b[0m\u001b[32;1m\u001b[1;3mThe row with the biggest difference between petal length and petal width is at index 122.  \n",
      "Final Answer: Row 122 has the biggest difference between petal length and petal width.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Row 122 has the biggest difference between petal length and petal width.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    prompt.format(\n",
    "        query=\"Which row has the biggest difference between petal length and petal width?\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "944ccda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m11 packages\u001b[0m \u001b[2min 83ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/7] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m7 packages\u001b[0m \u001b[2min 456ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.60.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.5\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install matplotlib~=3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "748614a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To show the distributions for each column visually, I can use histograms or other visualizations like kernel density estimates. Since the dataframe appears to contain numerical columns, a histogram for each column would be appropriate. I'll use matplotlib and pandas plotting capabilities to generate these visualizations.\n",
      "Action: python_repl_ast\n",
      "Action Input:\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Plot histograms for each column in the dataframe\n",
      "df.hist(bins=20, figsize=(12, 8))\n",
      "plt.tight_layout()\n",
      "plt.show()\u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe distributions for each column in the dataframe have been displayed visually using histograms. Each subplot represents the distribution of values for a specific column, allowing you to observe their frequency and spread.\n",
      "\n",
      "Final Answer: The distributions for each column have been visualized using histograms.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The distributions for each column have been visualized using histograms.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(prompt.format(query=\"Show the distributions for each column visually!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-with-lang-chain-2ed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
